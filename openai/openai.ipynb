{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```pip install openai```\n",
    "\n",
    "Get your key on https://platform.openai.com/api-keys\n",
    "\n",
    "After you need to instantiate a OpenAI object to load the client used to reach endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load the key\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# Create a client\n",
    "client = OpenAI(api_key=OPENAI_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoints\n",
    "\n",
    "OpenAi API has differents endpoints to make requests on differents services :\n",
    "- openai.chat.completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-B6vGTkQq1alAynSImHWf9i6UXIvWS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I\\'m unable to browse the internet or access websites, including the OpenAI documentation, as my knowledge was last updated in October 2021. However, I can provide you with a general overview of how endpoints typically work in the OpenAI Python module based on the information available up to that time.\\n\\nThe OpenAI Python module allows you to interact with various AI models, including GPT-3, by making requests to different endpoints. Here’s how it generally works:\\n\\n1. **Installation**: You start by installing the OpenAI Python package using pip:\\n   ```bash\\n   pip install openai\\n   ```\\n\\n2. **Authentication**: You need to set your API key to authorize requests. You can do this by setting the `OPENAI_API_KEY` environment variable or directly in your script:\\n   ```python\\n   import openai\\n   openai.api_key = \\'your-api-key\\'\\n   ```\\n\\n3. **Endpoints**:\\n   - **Completion endpoint**: This is used to generate text completions based on a prompt. You can call it like so:\\n     ```python\\n     response = openai.Completion.create(\\n         engine=\"text-davinci-003\", # or other models like text-curie-001, text-babbage-001, etc.\\n         prompt=\"Once upon a time\",\\n         max_tokens=50\\n     )\\n     print(response.choices[0].text.strip())\\n     ```\\n\\n   - **Chat endpoint**: For chat-based interactions, you might use the chat endpoint (for models like GPT-4), structured to handle a conversation:\\n     ```python\\n     response = openai.ChatCompletion.create(\\n         model=\"gpt-4\",\\n         messages=[\\n             {\"role\": \"user\", \"content\": \"Hello! How are you?\"},\\n         ]\\n     )\\n     print(response.choices[0].message[\\'content\\'])\\n     ```\\n\\n   - **Other endpoints**: Depending on the version of the API, there might be additional endpoints for image generation (e.g., DALL-E), file operations, or embeddings. Make sure to refer to the latest documentation for the details.\\n\\n4. **Parameters**: Each endpoint typically accepts various parameters that modify its behavior, such as:\\n   - `max_tokens`: Maximum number of tokens to generate.\\n   - `temperature`: Controls randomness (higher means more random).\\n   - `top_p`: Controls diversity via nucleus sampling.\\n\\n5. **Error Handling**: You should include error handling (`try`/`except`) to deal with potential exceptions such as reaching API limits or invalid inputs.\\n\\n6. **Rate Limits and Best Practices**: Respect the rate limits specified by OpenAI to avoid being throttled and follow best practices for efficient use of the API.\\n\\nTo get the most accurate and up-to-date information about specific endpoints and their usage, please visit the [OpenAI API documentation](https://platform.openai.com/docs) directly.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740989793, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_06737a9306', usage=CompletionUsage(completion_tokens=594, prompt_tokens=33, total_tokens=627, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How works the endpoints in openai module for python?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm unable to browse the internet or access websites, including the OpenAI documentation, as my knowledge was last updated in October 2021. However, I can provide you with a general overview of how endpoints typically work in the OpenAI Python module based on the information available up to that time.\n",
      "\n",
      "The OpenAI Python module allows you to interact with various AI models, including GPT-3, by making requests to different endpoints. Here’s how it generally works:\n",
      "\n",
      "1. **Installation**: You start by installing the OpenAI Python package using pip:\n",
      "   ```bash\n",
      "   pip install openai\n",
      "   ```\n",
      "\n",
      "2. **Authentication**: You need to set your API key to authorize requests. You can do this by setting the `OPENAI_API_KEY` environment variable or directly in your script:\n",
      "   ```python\n",
      "   import openai\n",
      "   openai.api_key = 'your-api-key'\n",
      "   ```\n",
      "\n",
      "3. **Endpoints**:\n",
      "   - **Completion endpoint**: This is used to generate text completions based on a prompt. You can call it like so:\n",
      "     ```python\n",
      "     response = openai.Completion.create(\n",
      "         engine=\"text-davinci-003\", # or other models like text-curie-001, text-babbage-001, etc.\n",
      "         prompt=\"Once upon a time\",\n",
      "         max_tokens=50\n",
      "     )\n",
      "     print(response.choices[0].text.strip())\n",
      "     ```\n",
      "\n",
      "   - **Chat endpoint**: For chat-based interactions, you might use the chat endpoint (for models like GPT-4), structured to handle a conversation:\n",
      "     ```python\n",
      "     response = openai.ChatCompletion.create(\n",
      "         model=\"gpt-4\",\n",
      "         messages=[\n",
      "             {\"role\": \"user\", \"content\": \"Hello! How are you?\"},\n",
      "         ]\n",
      "     )\n",
      "     print(response.choices[0].message['content'])\n",
      "     ```\n",
      "\n",
      "   - **Other endpoints**: Depending on the version of the API, there might be additional endpoints for image generation (e.g., DALL-E), file operations, or embeddings. Make sure to refer to the latest documentation for the details.\n",
      "\n",
      "4. **Parameters**: Each endpoint typically accepts various parameters that modify its behavior, such as:\n",
      "   - `max_tokens`: Maximum number of tokens to generate.\n",
      "   - `temperature`: Controls randomness (higher means more random).\n",
      "   - `top_p`: Controls diversity via nucleus sampling.\n",
      "\n",
      "5. **Error Handling**: You should include error handling (`try`/`except`) to deal with potential exceptions such as reaching API limits or invalid inputs.\n",
      "\n",
      "6. **Rate Limits and Best Practices**: Respect the rate limits specified by OpenAI to avoid being throttled and follow best practices for efficient use of the API.\n",
      "\n",
      "To get the most accurate and up-to-date information about specific endpoints and their usage, please visit the [OpenAI API documentation](https://platform.openai.com/docs) directly.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(content: str, model: str = \"gpt-4o-mini\", temperature: int = 2, max_tokens=100):\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "                \"temperature\": temperature,\n",
    "                \"max_tokens\": max_tokens,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating and transforming text\n",
    "If you don't specify a task, model is most likely to complete the prompt, otherwise you can:\n",
    "- Find & replace\n",
    "- Summarization\n",
    "- Content generation\n",
    "- Copyediting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is like a box of chocolates; you never know what you're gonna get.\" This famous quote from the movie *Forrest Gump* captures the idea that life is full of surprises and unpredictable moments. Just as each chocolate can have a different filling, every life experience can bring something unique. It's a reminder to embrace the uncertainty and enjoy the journey! What are your thoughts on this metaphor?\n",
      "That's a famous quote from the movie *Forrest Gump*! It suggests that life is full of surprises and you never know what you're going to get. Just like a box of chocolates, each experience can be sweet, bitter, or somewhere in between. It's a reminder to embrace the uncertainties and enjoy the journey. What are your thoughts on it?\n"
     ]
    }
   ],
   "source": [
    "# Most likely complete the prompt if you don't specify any instructions depending of the temperature parameter to add verbose\n",
    "content = get_response(content=\"Life is like a box of chocolates.\", temperature=5)\n",
    "print(content)\n",
    "content = get_response(content=\"Life is like a box of chocolates.\", temperature=0)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A plane is a vehicle that is typically powered by jet engines or propellers. It has wings and is designed to carry passengers and/or cargo through the air. Planes have become a ubiquitous part of modern society and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Planes are often associated with freedom, independence, and mobility.\n"
     ]
    }
   ],
   "source": [
    "# Find & replace task\n",
    "prompt=\"\"\"\n",
    "Replace car with plane and adjust phrase in the following text:\n",
    "\n",
    "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor.\n",
    "It has four wheels, and is designed to carry passengers and/or cargo on roads or highways.\n",
    "Cars have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods.\n",
    "Cars are often associated with freedom, independence, and mobility.\n",
    "\"\"\"\n",
    "\n",
    "content = get_response(content=prompt, temperature=2, max_tokens=100)\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Investment involves committing capital to various options—such as stocks, bonds, and real estate—with the aim of generating profit, requiring careful analysis of risks and rewards.  \n",
      "- Effective investment strategies, including diversification, can enhance long-term returns and financial security while minimizing the risk of losses.\n"
     ]
    }
   ],
   "source": [
    "# Summarize\n",
    "prompt=\"\"\"\n",
    "Summarize the following text into two concise bullet points:\n",
    "\n",
    "Investment refers to the act of committing money or capital to an enterprise with the expectation of obtaining an added income or profit in return.\n",
    "There are a variety of investment options available, including stocks, bonds, mutual funds, real estate, precious metals, and currencies.\n",
    "Making an investment decision requires careful analysis, assessment of risk, and evaluation of potential rewards.\n",
    "Good investments have the ability to produce high returns over the long term while minimizing risk.\n",
    "Diversification of investment portfolios reduces risk exposure.\n",
    "Investment can be a valuable tool for building wealth, generating income, and achieving financial security.\n",
    "It is important to be diligent and informed when investing to avoid losses.\n",
    "\"\"\"\n",
    "\n",
    "content = get_response(content=prompt, temperature=2, max_tokens=100)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Authentic Italian Flavors, Right in the Heart of Paris!\"\n"
     ]
    }
   ],
   "source": [
    "# Content generation. Increase temperature if you want more diversity\n",
    "prompt=\"Do create a slogan for a new italian restaurant in Paris city\"\n",
    "\n",
    "content = get_response(content=prompt, temperature=10, max_tokens=20)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "Assigning a label to information provided into the promt\n",
    "- Sentiment analysis (binary, ordinal, etc...)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt styles\n",
    "\n",
    "- Zero Shot prompting : Don't provide any example\n",
    "- One Shot prompting : One example provided\n",
    "- Few Shot promptint : Many examples provides"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
